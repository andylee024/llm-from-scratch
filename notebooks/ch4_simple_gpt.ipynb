{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ch 4 - Simple GPT\n",
    "This chapter focuses on implementing a mini-GPT NN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT-2 skeleton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"emb_dim\": 768, # Number of embedding dimensions\n",
    "    \"n_heads\": 12, # Number of attention heads\n",
    "    \"n_layers\": 12, # Number of layers\n",
    "    \"drop_rate\": 0.1, # Dropout rate\n",
    "    \"qkv_bias\": False# Query-Key-Value bias\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\"Implementation of multihead attention w/ parallel matrix processing\"\"\"\n",
    "\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "\n",
    "        # validate input dimensions\n",
    "        assert (d_out % num_heads == 0), \"d_out must be divisible by num_heads\"\n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.attention_dim = d_out // num_heads\n",
    "\n",
    "        # setup attention matrices\n",
    "        self.W_q = nn.Linear(in_features=d_in, out_features=d_out, bias=qkv_bias)\n",
    "        self.W_k = nn.Linear(in_features=d_in, out_features=d_out, bias=qkv_bias)\n",
    "        self.W_v = nn.Linear(in_features=d_in, out_features=d_out, bias=qkv_bias)\n",
    "        self.register_buffer('mask', torch.triu(torch.ones(context_length, context_length), diagonal=1))\n",
    "\n",
    "        # setup dropout\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        n, seq_length, _ = x.shape\n",
    "\n",
    "        # compute Q, K, V matrices\n",
    "        x_query = self.W_q(x)\n",
    "        x_key = self.W_k(x)\n",
    "        x_value = self.W_v(x)\n",
    "\n",
    "        # reshape to separate into Q = [Q1, Q2, ...], K = [K1, K2, ...]\n",
    "        x_query = x_query.view(n, seq_length, self.num_heads, self.attention_dim)\n",
    "        x_query = x_query.transpose(1, 2) # (n, num_heads, seq_length, attention_dim)\n",
    "\n",
    "        x_key = x_key.view(n, seq_length, self.num_heads, self.attention_dim)\n",
    "        x_key = x_key.transpose(1, 2) # (n, num_heads, seq_length, attention_dim)\n",
    "        x_key = x_key.transpose(2, 3) # (n, num_heads, attention_dim, seq_length)\n",
    "\n",
    "        x_value = x_value.view(n, seq_length, self.num_heads, self.attention_dim)\n",
    "        x_value = x_value.transpose(1, 2) # (n, num_heads, seq_length, attention_dim)\n",
    "\n",
    "        # compute attention scores (per-head)\n",
    "        dk_constant = x_key.shape[-1] ** -0.5\n",
    "        mask_context = self.mask.bool()[:seq_length, :seq_length] \n",
    "        attention_scores = (x_query @ x_key)\n",
    "        attention_scores.masked_fill_(mask_context, -torch.inf)\n",
    "\n",
    "        # compute attention weights \n",
    "        # note : no dropout on scores (b/c dropout on -inf is not well-defined)\n",
    "        attention_weights = torch.softmax(attention_scores * dk_constant, dim=-1)\n",
    "        attention_weights = self.dropout(attention_weights)\n",
    "\n",
    "        # compute context\n",
    "        context = attention_weights @ x_value\n",
    "\n",
    "        # reshape back to (n, seq_length, d_out)\n",
    "        context = context.contiguous().view(n, seq_length, self.d_out)\n",
    "\n",
    "        return context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class DummyGPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[DummyTransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])]\n",
    "        )\n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "\n",
    "        # read input X\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "\n",
    "        # map X to embedding space\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds\n",
    "\n",
    "        # apply dropout\n",
    "        x = self.drop_emb(x)\n",
    "\n",
    "        # apply transformer blocks\n",
    "        x = self.trf_blocks(x)\n",
    "\n",
    "        # apply layer norm\n",
    "        x = self.final_norm(x)\n",
    "\n",
    "        # apply FF network \n",
    "        logits = self.out_head(x)\n",
    "        return logits\n",
    "\n",
    "class DummyTransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift\n",
    "    \n",
    "class GELU(nn.Module):\n",
    "    \"\"\"Activation function that's smoother than RELU\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2.0 / torch.pi)) * (x + 0.044715 * torch.pow(x, 3))\n",
    "        ))\n",
    "    \n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
    "            GELU(),\n",
    "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n",
    ")\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "    \n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in=cfg[\"emb_dim\"],\n",
    "            d_out=cfg[\"emb_dim\"],\n",
    "            context_length=cfg[\"context_length\"],\n",
    "            num_heads=cfg[\"n_heads\"],\n",
    "            dropout=cfg[\"drop_rate\"],\n",
    "            qkv_bias=cfg[\"qkv_bias\"])\n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut\n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples - Scratchpad \n",
    "A list of tiny examples to demonstrate how each class works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape torch.Size([2, 4])\n",
      "tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n"
     ]
    }
   ],
   "source": [
    "# example : tokenizing text\n",
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "batch = []\n",
    "txt1 = \"Every effort moves you\"\n",
    "txt2 = \"Every day holds a\"\n",
    "batch.append(torch.tensor(tokenizer.encode(txt1)))\n",
    "batch.append(torch.tensor(tokenizer.encode(txt2)))\n",
    "batch = torch.stack(batch, dim=0)\n",
    "print(\"shape\", batch.shape)\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([2, 4, 50257])\n",
      "tensor([[[-0.5998,  0.1788, -0.4855,  ..., -1.0338,  0.1756, -0.3791],\n",
      "         [-0.3048,  0.1200,  0.3618,  ..., -0.2633,  1.0311,  0.5753],\n",
      "         [ 0.4025,  1.0698, -0.1543,  ...,  0.7827,  0.0786,  0.5037],\n",
      "         [ 0.0938,  1.6024, -0.6251,  ...,  0.8712, -0.1122, -0.3924]],\n",
      "\n",
      "        [[-0.9718, -0.0670, -0.6994,  ..., -1.1791, -0.3173, -0.4363],\n",
      "         [-0.6117,  0.6015, -0.0475,  ..., -0.0795,  0.1833,  0.7967],\n",
      "         [ 0.1158,  0.7813, -0.1099,  ...,  0.0522, -0.1281,  0.1061],\n",
      "         [ 0.1734, -0.6275,  0.1344,  ...,  1.7331, -0.2619, -0.2139]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# example : running the dummy network\n",
    "torch.manual_seed(123)\n",
    "model = DummyGPTModel(GPT_CONFIG_124M)\n",
    "logits = model(batch)\n",
    "print(\"Output shape:\", logits.shape)\n",
    "print(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExampleDeepNeuralNetwork(nn.Module):\n",
    "    def __init__(self, layer_sizes, use_shortcut):\n",
    "        super().__init__()\n",
    "        self.use_shortcut = use_shortcut\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.Sequential(nn.Linear(layer_sizes[0], layer_sizes[1]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[1], layer_sizes[2]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[2], layer_sizes[3]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[3], layer_sizes[4]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[4], layer_sizes[5]), GELU())\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "\n",
    "            # run layer \n",
    "            layer_output = layer(x)\n",
    "\n",
    "            # if skip connection, then you sum the original (x) + layer-output and feed to next network\n",
    "            if self.use_shortcut and x.shape == layer_output.shape:\n",
    "                x = x + layer_output\n",
    "\n",
    "            # if no skip connection, then just layer_output = x, the input to next layer\n",
    "            else:\n",
    "                x = layer_output\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--model w/out shortcut--\n",
      "layers.0.0.weight has gradient mean of 0.00020173587836325169\n",
      "layers.1.0.weight has gradient mean of 0.0001201116101583466\n",
      "layers.2.0.weight has gradient mean of 0.0007152041653171182\n",
      "layers.3.0.weight has gradient mean of 0.001398873864673078\n",
      "layers.4.0.weight has gradient mean of 0.005049646366387606\n",
      "\n",
      "\n",
      "--model w/ shortcut--\n",
      "layers.0.0.weight has gradient mean of 0.0014432319439947605\n",
      "layers.1.0.weight has gradient mean of 0.004846962168812752\n",
      "layers.2.0.weight has gradient mean of 0.0041389018297195435\n",
      "layers.3.0.weight has gradient mean of 0.00591512955725193\n",
      "layers.4.0.weight has gradient mean of 0.03265950828790665\n"
     ]
    }
   ],
   "source": [
    "layer_sizes = [3, 3, 3, 3, 3, 1]\n",
    "sample_input = torch.tensor([[1., 0., -1.]])\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# Model without shortcut\n",
    "model_without_shortcut = ExampleDeepNeuralNetwork(layer_sizes, use_shortcut=False)\n",
    "model_with_shortcut = ExampleDeepNeuralNetwork(layer_sizes, use_shortcut=True)\n",
    "\n",
    "# Function to compute gradients in the model's backward pass\n",
    "def print_gradients(model, x):\n",
    "    output = model(x)  # Forward pass\n",
    "    target = torch.tensor([[0.]])\n",
    "    loss_fn = nn.MSELoss()\n",
    "    loss = loss_fn(output, target)  # Calculates loss based on how close the target and output are\n",
    "    loss.backward()  # Backward pass to calculate the gradients\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            print(f\"{name} has gradient mean of {param.grad.abs().mean().item()}\")\n",
    "\n",
    "# Call the function to print gradients\n",
    "print(\"--model w/out shortcut--\")\n",
    "print_gradients(model_without_shortcut, sample_input)\n",
    "print(\"\\n\\n--model w/ shortcut--\")\n",
    "print_gradients(model_with_shortcut, sample_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 4, 768])\n",
      "Output shape: torch.Size([2, 4, 768])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "x = torch.rand(2, 4, 768)\n",
    "block = TransformerBlock(GPT_CONFIG_124M)\n",
    "output = block(x)\n",
    "print(\"Input shape:\", x.shape)\n",
    "print(\"Output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
