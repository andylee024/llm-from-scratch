{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ch 4 - Implement GPT-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities - previous chapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, text, tokenizer, max_length, stride):\n",
    "        self.max_length = max_length\n",
    "        self.stride = stride\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "        # build dataset\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "        self._build_dataset(text)\n",
    "\n",
    "    def _build_dataset(self, text):\n",
    "\n",
    "        context_length = self.max_length\n",
    "        token_ids = self.tokenizer.encode(text)\n",
    "        final_token_index = len(token_ids) - self.max_length\n",
    "\n",
    "        for i in range(0, final_token_index, self.stride):\n",
    "            input_chunk = token_ids[i: i+context_length]\n",
    "            target_chunk = token_ids[i+1 : i+1+context_length]\n",
    "\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]\n",
    "\n",
    "def create_dataloader_v1(txt, batch_size=4, max_length=256, stride=128, shuffle=True, drop_last=True, num_workers=0):\n",
    "\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "    dataset = GPTDatasetV1(text=txt, tokenizer=tokenizer, max_length=max_length, stride=stride)\n",
    "\n",
    "    dataloader = DataLoader(dataset=dataset,\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=shuffle,\n",
    "                            drop_last=drop_last,\n",
    "                            num_workers=num_workers)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 256,  # Context length\n",
    "    \"emb_dim\": 768, # Number of embedding dimensions\n",
    "    \"n_heads\": 12, # Number of attention heads\n",
    "    \"n_layers\": 12, # Number of transformer layers\n",
    "    \"drop_rate\": 0.1, # Dropout rate\n",
    "    \"qkv_bias\": False# Query-Key-Value bias\n",
    "}\n",
    "\n",
    "\n",
    "GPT2_LARGE_CONFIG = {\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"emb_dim\": 1280, # Number of embedding dimensions\n",
    "    \"n_heads\": 20, # Number of attention heads\n",
    "    \"n_layers\": 36, # Number of transformer layers\n",
    "    \"drop_rate\": 0.1, # Dropout rate\n",
    "    \"qkv_bias\": False# Query-Key-Value bias\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\"Implementation of multihead attention w/ parallel matrix processing\"\"\"\n",
    "\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "\n",
    "        # validate input dimensions\n",
    "        assert (d_out % num_heads == 0), \"d_out must be divisible by num_heads\"\n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.attention_dim = d_out // num_heads\n",
    "\n",
    "        # setup attention matrices\n",
    "        self.W_query = nn.Linear(in_features=d_in, out_features=d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(in_features=d_in, out_features=d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(in_features=d_in, out_features=d_out, bias=qkv_bias)\n",
    "        self.register_buffer('mask', torch.triu(torch.ones(context_length, context_length), diagonal=1))\n",
    "\n",
    "        # setup dropout\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # setup linear\n",
    "        self.out_proj = nn.Linear(d_out, d_out)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        n, seq_length, _ = x.shape\n",
    "\n",
    "        # compute Q, K, V matrices\n",
    "        x_query = self.W_query(x)\n",
    "        x_key = self.W_key(x)\n",
    "        x_value = self.W_value(x)\n",
    "\n",
    "        # reshape to separate into Q = [Q1, Q2, ...], K = [K1, K2, ...]\n",
    "        x_query = x_query.view(n, seq_length, self.num_heads, self.attention_dim)\n",
    "        x_query = x_query.transpose(1, 2) # (n, num_heads, seq_length, attention_dim)\n",
    "\n",
    "        x_key = x_key.view(n, seq_length, self.num_heads, self.attention_dim)\n",
    "        x_key = x_key.transpose(1, 2) # (n, num_heads, seq_length, attention_dim)\n",
    "        x_key = x_key.transpose(2, 3) # (n, num_heads, attention_dim, seq_length)\n",
    "\n",
    "        x_value = x_value.view(n, seq_length, self.num_heads, self.attention_dim)\n",
    "        x_value = x_value.transpose(1, 2) # (n, num_heads, seq_length, attention_dim)\n",
    "\n",
    "        # compute attention scores (per-head)\n",
    "        dk_constant = x_key.shape[-1] ** -0.5\n",
    "        mask_context = self.mask.bool()[:seq_length, :seq_length] \n",
    "        attention_scores = (x_query @ x_key)\n",
    "        attention_scores.masked_fill_(mask_context, -torch.inf)\n",
    "\n",
    "        # compute attention weights \n",
    "        # note : no dropout on scores (b/c dropout on -inf is not well-defined)\n",
    "        attention_weights = torch.softmax(attention_scores * dk_constant, dim=-1)\n",
    "        attention_weights = self.dropout(attention_weights)\n",
    "\n",
    "        # compute context\n",
    "        context = attention_weights @ x_value\n",
    "\n",
    "        # reshape back to (n, seq_length, d_out)\n",
    "        context = context.contiguous().view(n, seq_length, self.d_out)\n",
    "        \n",
    "        # apply linear layer\n",
    "        return self.out_proj(context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module):\n",
    "\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        self.trf_blocks = nn.Sequential(*[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # read input X\n",
    "        _, seq_len = x.shape\n",
    "\n",
    "        # map X to embedding space\n",
    "        # embedding matrices take list of indices\n",
    "        tok_embeds = self.tok_emb(x)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=x.device))\n",
    "        x = tok_embeds + pos_embeds\n",
    "\n",
    "        # process embed(X) through architecture\n",
    "        # note : 12 transformer blocks is main processing\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x) \n",
    "        x = self.final_norm(x)\n",
    "\n",
    "        logits = self.out_head(x)\n",
    "        return logits\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift\n",
    "    \n",
    "class GELU(nn.Module):\n",
    "    \"\"\"Activation function that's smoother than RELU\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2.0 / torch.pi)) * (x + 0.044715 * torch.pow(x, 3))\n",
    "        ))\n",
    "    \n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
    "            GELU(),\n",
    "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n",
    ")\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "    \n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in=cfg[\"emb_dim\"],\n",
    "            d_out=cfg[\"emb_dim\"],\n",
    "            context_length=cfg[\"context_length\"],\n",
    "            num_heads=cfg[\"n_heads\"],\n",
    "            dropout=cfg[\"drop_rate\"],\n",
    "            qkv_bias=cfg[\"qkv_bias\"])\n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut\n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_simple(model, x, max_new_tokens=100, context_size=10):\n",
    "\n",
    "    # iteratively generate new tokens (up to a limit)\n",
    "    for _ in range(max_new_tokens):\n",
    "\n",
    "        # get context for prediction\n",
    "        # note: equivalent to x[:, seq_length - context_size:]\n",
    "        x_conditioned = x[:, -context_size:] \n",
    "\n",
    "        # run model to predict next token\n",
    "        with torch.no_grad():\n",
    "            logits = model(x_conditioned)\n",
    "\n",
    "        # decode next token prediction\n",
    "        next_token_logits = logits[:, -1, :]\n",
    "        next_token_probabilities = torch.softmax(next_token_logits, dim=-1)\n",
    "        next_token_prediction = torch.argmax(next_token_probabilities, dim=-1, keepdim=True)\n",
    "        # next_token_prediction = torch.multinomial(next_token_probabilities, dim=-1, keepdim=True)\n",
    "\n",
    "        # create next context \n",
    "        x = torch.cat((x_conditioned, next_token_prediction), dim=1)\n",
    "\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch shape: torch.Size([2, 4])\n",
      "logits_shape : torch.Size([2, 4, 50257])\n",
      "Total parameters in the full model: 838220800\n",
      "Total parameters in the output head: 64328960\n",
      "Total parameters in the transformer block: 708249600\n",
      "Total parameters in a single attention layer: 6554880\n",
      "Total parameters in a single feed-forward layer: 13113600\n",
      "Total size of the model: 3197.56 MB\n"
     ]
    }
   ],
   "source": [
    "# set seed\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# setup tokenizer\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "# setup data\n",
    "batch = []\n",
    "txt1 = \"Every effort moves you\"\n",
    "txt2 = \"Every day holds a\"\n",
    "batch.append(torch.tensor(tokenizer.encode(txt1)))\n",
    "batch.append(torch.tensor(tokenizer.encode(txt2)))\n",
    "batch = torch.stack(batch, dim=0) # (n x seq_length), each element is list of indices [idx1, idx2, ...]\n",
    "print(f\"batch shape: {batch.shape}\")\n",
    "\n",
    "# instantiate model\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "gpt2_large_model = GPTModel(GPT2_LARGE_CONFIG)\n",
    "logits = model(batch)\n",
    "\n",
    "# inspect output\n",
    "print(f\"logits_shape : {logits.shape}\")\n",
    "\n",
    "# inspect parameters\n",
    "# exercise 4.1\n",
    "model = GPTModel(GPT2_LARGE_CONFIG)\n",
    "total_params_full = sum(p.numel() for p in model.parameters())\n",
    "total_params_out_head = sum(p.numel() for p in model.out_head.parameters())\n",
    "total_params_transformer_block = sum(p.numel() for p in model.trf_blocks.parameters())\n",
    "\n",
    "trf_block = model.trf_blocks[0]\n",
    "trf_attn = trf_block.att\n",
    "trf_ff = trf_block.ff\n",
    "total_params_single_attn = sum(p.numel() for p in trf_attn.parameters())\n",
    "total_params_single_ff = sum(p.numel() for p in trf_ff.parameters())\n",
    "\n",
    "# computer parameters\n",
    "print(f\"Total parameters in the full model: {total_params_full}\")\n",
    "print(f\"Total parameters in the output head: {total_params_out_head}\")\n",
    "print(f\"Total parameters in the transformer block: {total_params_transformer_block}\")\n",
    "print(f\"Total parameters in a single attention layer: {total_params_single_attn}\")\n",
    "print(f\"Total parameters in a single feed-forward layer: {total_params_single_ff}\")\n",
    "\n",
    "# compute memory requirements\n",
    "total_size_bytes = total_params_full * 4\n",
    "total_size_mb = total_size_bytes / (1024 * 1024)\n",
    "print(f\"Total size of the model: {total_size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ch. 5 - Pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_text : Every effort moves you wraps Booster iteratorakuyaChance Ib reluctant BjreeILL\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0)\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "# initialize start context\n",
    "start_context = \"Hello, I am\"\n",
    "start_context = \"Every effort moves you\"\n",
    "\n",
    "# setup\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval()\n",
    "\n",
    "# prediction\n",
    "token_ids = generate_text_simple(model=model,\n",
    "                                 x=text_to_token_ids(start_context, tokenizer),\n",
    "                                 max_new_tokens=10,\n",
    "                                 context_size=GPT_CONFIG_124M[\"context_length\"])\n",
    "output_text = token_ids_to_text(token_ids, tokenizer)\n",
    "print(f\"output_text : {output_text}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Small training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    \"\"\"Calculates loss for a single batch given input & target\"\"\"\n",
    "    input_batch = input_batch.to(device)\n",
    "    target_batch = target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(\n",
    "        logits.flatten(0, 1), target_batch.flatten()\n",
    "    )\n",
    "    return loss\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    \"\"\"Iterates through data loader and calculates loss per batch\"\"\"\n",
    "    total_loss = 0.\n",
    "\n",
    "    # setup\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "\n",
    "    # iterate through batches , compute losses\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return total_loss / num_batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 11.019258711073133\n",
      "Validation loss: 11.028642654418945\n"
     ]
    }
   ],
   "source": [
    "# Example : 1 training loops\n",
    "\n",
    "# input data\n",
    "# file_path = \"/Users/andylee/Projects/llm-from-scratch/data/the-verdict.txt\"\n",
    "file_path = \"/datasets/the-verdict/the-verdict.txt\"\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    text_data = file.read()\n",
    "\n",
    "# split to train & validation batch\n",
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]\n",
    "\n",
    "# create data loaders\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "# setup devices\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "model.to(device)\n",
    "\n",
    "# run 1 single iteration of loss\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(\n",
    "            train_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "        val_loss = calc_loss_loader(\n",
    "            val_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    \"\"\"Run a single forward pass of model to get predicted tokens\"\"\"\n",
    "\n",
    "    # set to eval mode\n",
    "    model.eval()\n",
    "\n",
    "    # encode X \n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "\n",
    "    # predict y\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(model=model, x=encoded, max_new_tokens=50, context_size=context_size)\n",
    "\n",
    "    # get text(y)\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text)\n",
    "\n",
    "    # revert to train mode\n",
    "    model.train()\n",
    "\n",
    "\n",
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs, eval_freq, eval_iter, start_context, tokenizer):\n",
    "    \"\"\"Training loop of NN\"\"\"\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "\n",
    "        # iterate through training batches \n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            # print losses based on eval_freq\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        # generate new token predictions after each epoch \n",
    "        generate_and_print_sample(model, tokenizer, device, start_context)\n",
    "    \n",
    "    return train_losses, val_losses, track_tokens_seen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 9.920, Val loss 10.086\n",
      "Ep 1 (Step 000005): Train loss 7.934, Val loss 8.307\n",
      "I'm a GPT (Andy made me).\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Ep 2 (Step 000010): Train loss 6.486, Val loss 7.043\n",
      "Ep 2 (Step 000015): Train loss 5.884, Val loss 6.584\n",
      "I'm a GPT (Andy made me), and the\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Ep 3 (Step 000020): Train loss 5.233, Val loss 6.423\n",
      "Ep 3 (Step 000025): Train loss 4.485, Val loss 6.340\n",
      "I'm a GPT (Andy made me) of the picture to the picture. Gisburn, and I was, and the picture.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Ep 4 (Step 000030): Train loss 3.907, Val loss 6.262\n",
      "Ep 4 (Step 000035): Train loss 3.509, Val loss 6.220\n",
      "I'm a GPT (Andy made me) the.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\"I had been the picture the fact of the.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\"Oh, and he had been the man of the picture.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Ep 5 (Step 000040): Train loss 2.730, Val loss 6.205\n",
      "I'm a GPT (Andy made me) was, I had the fact with the last I had been the end of the!\n",
      "\n",
      "\"Oh, I had been his pictures--that_ as he had been his pictures, I had always, I was his own, I had always,\n",
      "Ep 6 (Step 000045): Train loss 2.332, Val loss 6.238\n",
      "Ep 6 (Step 000050): Train loss 1.775, Val loss 6.262\n",
      "I'm a GPT (Andy made me) was, the picture, and Mrs.\n",
      "\n",
      "\"I was the, and the fact, and I had a it, his I had been the his pictures--the, and I was \"There were, in his own, he had been,\n",
      "Ep 7 (Step 000055): Train loss 1.560, Val loss 6.310\n",
      "Ep 7 (Step 000060): Train loss 0.971, Val loss 6.295\n",
      "I'm a GPT (Andy made me),, his pictures--I was, in a little: \", I was the, I was the Mrs. I was his pictures.\n",
      "\n",
      "\"I was dead.\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Ep 8 (Step 000065): Train loss 0.665, Val loss 6.359\n",
      "Ep 8 (Step 000070): Train loss 0.490, Val loss 6.396\n",
      "I'm a GPT (Andy made me),, his pictures,, the, in the her, the, the, in the, the the man, the moment-- the the my the donkey again. I, the, my the the the hour in the her so. Gisburn\n",
      "Ep 9 (Step 000075): Train loss 0.299, Val loss 6.462\n",
      "Ep 9 (Step 000080): Train loss 0.187, Val loss 6.552\n",
      "I'm a GPT (Andy made me), as his pictures--so handsome, the in the house.\"\n",
      "\n",
      "\" went on the it all his: \"Be dissatisfied with your leisure!\" I had again.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Ep 10 (Step 000085): Train loss 0.106, Val loss 6.562\n",
      "I'm a GPT (Andy made me), as the deep the irony the tips the was vindicated--she's an awful simpleton, you know, the moment--as Jack himself, the in the honour the wander up and down the room, stopping now and then beneath the picture.\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "# make the GPT model\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "\n",
    "# setup training optimizer\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=0.0004, weight_decay=0.1\n",
    ")\n",
    "\n",
    "# start training!! \n",
    "num_epochs = 3\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=\"I'm a GPT (Andy made me)\", tokenizer=tokenizer\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI - GPT 2 (load weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, idx, max_new_tokens, context_size,\n",
    "             temperature=0.0, top_k=None, eos_id=None):\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "        if top_k is not None:\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(\n",
    "                logits < min_val,\n",
    "                torch.tensor(float('-inf')).to(logits.device),\n",
    "                logits\n",
    "            )\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
    "        if idx_next == eos_id:\n",
    "            break\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "    return idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/124M/checkpoint\n",
      "File already exists and is up-to-date: gpt2/124M/encoder.json\n",
      "File already exists and is up-to-date: gpt2/124M/hparams.json\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2/124M/vocab.bpe\n",
      "Settings: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n",
      "Parameter dictionary keys: dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n",
      "-0.11010301\n",
      "Token embedding weight tensor dimensions: (50257, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-13 10:36:45.621935: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 154389504 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# step 1 : download files (tool)\n",
    "# import urllib.request\n",
    "# url = (\n",
    "#     \"https://raw.githubusercontent.com/rasbt/\"\n",
    "#     \"LLMs-from-scratch/main/ch05/\"\n",
    "#     \"01_main-chapter-code/gpt_download.py\"\n",
    "# )\n",
    "# filename = url.split('/')[-1]\n",
    "# urllib.request.urlretrieve(url, filename)\n",
    "\n",
    "# step 2 : load open AI weights\n",
    "from gpt_download import download_and_load_gpt2\n",
    "settings, params = download_and_load_gpt2(\n",
    "    model_size=\"124M\", models_dir=\"gpt2\"\n",
    ")\n",
    "\n",
    "print(\"Settings:\", settings)\n",
    "print(\"Parameter dictionary keys:\", params.keys())\n",
    "print(params[\"wte\"][0, 0])\n",
    "print(\"Token embedding weight tensor dimensions:\", params[\"wte\"].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load openAI weights & transfer to our model\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "model_name = \"gpt2-small (124M)\"\n",
    "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
    "NEW_CONFIG.update(model_configs[model_name])\n",
    "NEW_CONFIG.update({\"context_length\": 1024})\n",
    "NEW_CONFIG.update({\"qkv_bias\": True})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_weights_into_gpt(gpt, params):\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
    "    for b in range(len(params[\"blocks\"])):\n",
    "        q_w, k_w, v_w = np.split((params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.weight = assign(gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
    "        gpt.trf_blocks[b].att.W_key.weight = assign(gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign(gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
    "        q_b, k_b, v_b = np.split((params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign(gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign(gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign(gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign(gpt.trf_blocks[b].att.out_proj.weight, params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign(gpt.trf_blocks[b].att.out_proj.bias, params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign(gpt.trf_blocks[b].ff.layers[0].weight, params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign(gpt.trf_blocks[b].ff.layers[0].bias, params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign(gpt.trf_blocks[b].ff.layers[2].weight, params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign(gpt.trf_blocks[b].ff.layers[2].bias, params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    "        gpt.trf_blocks[b].norm1.scale = assign(gpt.trf_blocks[b].norm1.scale, params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm1.shift = assign(gpt.trf_blocks[b].norm1.shift, params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "        gpt.trf_blocks[b].norm2.scale = assign(gpt.trf_blocks[b].norm2.scale, params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm2.shift = assign(gpt.trf_blocks[b].norm2.shift, params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you as as the health, the same] (and that means - of Greece said: eight years after my boy (TITUN\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "gpt1 = GPTModel(NEW_CONFIG)\n",
    "load_weights_into_gpt(gpt1, params)\n",
    "gpt1.to(device)\n",
    "gpt1.eval()\n",
    "\n",
    "token_ids = generate(model=gpt,\n",
    "                     idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device), \n",
    "                     max_new_tokens=25,\n",
    "                     context_size=NEW_CONFIG[\"context_length\"],\n",
    "                     top_k=50,\n",
    "                     temperature=1.5)\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you the. If a that,\n",
      "\n",
      "\n",
      "This article...gone The list its use of which was introduced environmental. We get\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scratchpad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model weights\n",
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "\n",
    "# load model weights\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(torch.load(\"model.pth\", map_location=device))\n",
    "model.eval()\n",
    "\n",
    "# save model weights & state\n",
    "torch.save({\n",
    "    \"model_state_dict\": model.state_dict(),\n",
    "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "    },\n",
    "    \"model_and_optimizer.pth\"\n",
    ")\n",
    "\n",
    "# save a checkpoint\n",
    "checkpoint = torch.load(\"model_and_optimizer.pth\", map_location=device) \n",
    "model = GPTModel(GPT_CONFIG_124M) \n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=0.1) \n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "model.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilistic Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "closer : 142\n",
      "every : 82\n",
      "effort : 93\n",
      "forward : 168\n",
      "inches : 114\n",
      "moves : 83\n",
      "pizza : 62\n",
      "toward : 165\n",
      "you : 91\n",
      "tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# intuition - probabilistic sampling\n",
    "def softmax_with_temperature(logits, temperature):\n",
    "    scaled_logits = logits / temperature\n",
    "    return torch.softmax(scaled_logits, dim=0)\n",
    "\n",
    "def print_sampled_tokens(probabilities):\n",
    "    torch.manual_seed(123)\n",
    "    sample = [torch.multinomial(probabilities, num_samples=1).item()\n",
    "             for i in range(1000)]\n",
    "    sampled_ids = torch.bincount(torch.tensor(sample))\n",
    "    for i, freq in enumerate(sampled_ids):\n",
    "        print(f\"{inverse_vocab[i]} : {freq}\")\n",
    "\n",
    "vocab = {\n",
    "    \"closer\": 0,\n",
    "    \"every\": 1,\n",
    "    \"effort\": 2,\n",
    "    \"forward\": 3,\n",
    "    \"inches\": 4,\n",
    "    \"moves\": 5,\n",
    "    \"pizza\": 6,\n",
    "    \"toward\": 7,\n",
    "    \"you\": 8,\n",
    "}\n",
    "inverse_vocab = {v: k for k, v in vocab.items()}\n",
    "next_token_logits = torch.tensor(\n",
    "    [4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
    ")\n",
    "next_token_probabilities = softmax_with_temperature(next_token_logits, temperature=10.)\n",
    "print_sampled_tokens(next_token_probabilities)\n",
    "\n",
    "# top k sampling \n",
    "top_k = 3\n",
    "top_logits, top_pos = torch.topk(next_token_logits, top_k)\n",
    "new_logits = torch.where(\n",
    "    condition=next_token_logits < top_logits[-1],\n",
    "    input=torch.tensor(float('-inf')),\n",
    "    other=next_token_logits)\n",
    "topk_probabilities = torch.softmax(new_logits, dim=0)\n",
    "print(topk_probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you?\"\n",
      "\"Oh, I felt able to face the fact with equanimity. Poor he had been dead.\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# after model is trained , we should get deterministic outputs b/c the weight is always the same\n",
    "model.to(\"cpu\")\n",
    "model.eval()\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    x=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=25,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(\n",
    "        epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\"\n",
    "    )\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax2 = ax1.twiny()\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skip-connection intuition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--model w/out shortcut--\n",
      "layers.0.0.weight has gradient mean of 0.00020173584925942123\n",
      "layers.1.0.weight has gradient mean of 0.00012011159560643137\n",
      "layers.2.0.weight has gradient mean of 0.0007152040489017963\n",
      "layers.3.0.weight has gradient mean of 0.0013988736318424344\n",
      "layers.4.0.weight has gradient mean of 0.005049645435065031\n",
      "\n",
      "\n",
      "--model w/ shortcut--\n",
      "layers.0.0.weight has gradient mean of 0.0014432291500270367\n",
      "layers.1.0.weight has gradient mean of 0.004846952389925718\n",
      "layers.2.0.weight has gradient mean of 0.004138893447816372\n",
      "layers.3.0.weight has gradient mean of 0.005915115587413311\n",
      "layers.4.0.weight has gradient mean of 0.032659437507390976\n"
     ]
    }
   ],
   "source": [
    "# Function to compute gradients in the model's backward pass\n",
    "def print_gradients(model, x):\n",
    "    output = model(x)  # Forward pass\n",
    "    target = torch.tensor([[0.]])\n",
    "    loss_fn = nn.MSELoss()\n",
    "    loss = loss_fn(output, target)  # Calculates loss based on how close the target and output are\n",
    "    loss.backward()  # Backward pass to calculate the gradients\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            print(f\"{name} has gradient mean of {param.grad.abs().mean().item()}\")\n",
    "\n",
    "class ExampleDeepNeuralNetwork(nn.Module):\n",
    "    def __init__(self, layer_sizes, use_shortcut):\n",
    "        super().__init__()\n",
    "        self.use_shortcut = use_shortcut\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.Sequential(nn.Linear(layer_sizes[0], layer_sizes[1]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[1], layer_sizes[2]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[2], layer_sizes[3]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[3], layer_sizes[4]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[4], layer_sizes[5]), GELU())\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "\n",
    "            # run layer \n",
    "            layer_output = layer(x)\n",
    "\n",
    "            # if skip connection, then you sum the original (x) + layer-output and feed to next network\n",
    "            if self.use_shortcut and x.shape == layer_output.shape:\n",
    "                x = x + layer_output\n",
    "\n",
    "            # if no skip connection, then just layer_output = x, the input to next layer\n",
    "            else:\n",
    "                x = layer_output\n",
    "\n",
    "        return x\n",
    "    \n",
    "\n",
    "layer_sizes = [3, 3, 3, 3, 3, 1]\n",
    "sample_input = torch.tensor([[1., 0., -1.]])\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# Model without shortcut\n",
    "model_without_shortcut = ExampleDeepNeuralNetwork(layer_sizes, use_shortcut=False)\n",
    "model_with_shortcut = ExampleDeepNeuralNetwork(layer_sizes, use_shortcut=True)\n",
    "\n",
    "# Call the function to print gradients\n",
    "print(\"--model w/out shortcut--\")\n",
    "print_gradients(model_without_shortcut, sample_input)\n",
    "print(\"\\n\\n--model w/ shortcut--\")\n",
    "print_gradients(model_with_shortcut, sample_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
