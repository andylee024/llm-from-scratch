{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM from scratch\n",
    "This notebook contains code for LLM-from-scratch book."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ch 3 - Attention Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.3 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/andylee/anaconda3/envs/llm/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/andylee/anaconda3/envs/llm/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/andylee/anaconda3/envs/llm/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/andylee/anaconda3/envs/llm/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Users/andylee/anaconda3/envs/llm/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Users/andylee/anaconda3/envs/llm/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Users/andylee/anaconda3/envs/llm/lib/python3.11/asyncio/events.py\", line 84, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/andylee/anaconda3/envs/llm/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/andylee/anaconda3/envs/llm/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/andylee/anaconda3/envs/llm/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/andylee/anaconda3/envs/llm/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/Users/andylee/anaconda3/envs/llm/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/andylee/anaconda3/envs/llm/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/andylee/anaconda3/envs/llm/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/andylee/anaconda3/envs/llm/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3044, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/andylee/anaconda3/envs/llm/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3099, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/andylee/anaconda3/envs/llm/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/andylee/anaconda3/envs/llm/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3303, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/andylee/anaconda3/envs/llm/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3486, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/andylee/anaconda3/envs/llm/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3546, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/k8/kfnfm34s37gb64xyqjkjztz40000gn/T/ipykernel_35219/4049959471.py\", line 1, in <module>\n",
      "    import torch\n",
      "  File \"/Users/andylee/anaconda3/envs/llm/lib/python3.11/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/andylee/anaconda3/envs/llm/lib/python3.11/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/andylee/anaconda3/envs/llm/lib/python3.11/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/andylee/anaconda3/envs/llm/lib/python3.11/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/andylee/anaconda3/envs/llm/lib/python3.11/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/andylee/anaconda3/envs/llm/lib/python3.11/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "-- attention --\n",
      "token[1]: tensor([0.5500, 0.8700, 0.6600])\n",
      "A(.) is affinity\n",
      "w(0) = A(x(1), x(0)) : tensor([0.1455])\n",
      "w(1) = A(x(1), x(1)) : tensor([0.2278])\n",
      "w(2) = A(x(1), x(2)) : tensor([0.2249])\n",
      "w(3) = A(x(1), x(3)) : tensor([0.1285])\n",
      "w(4) = A(x(1), x(4)) : tensor([0.1077])\n",
      "w(5) = A(x(1), x(5)) : tensor([0.1656])\n",
      "\n",
      "\n",
      "-- context --\n",
      "list_context_vectors :  torch.Size([6, 3])\n",
      "z(0) = w(0)* x[0] : tensor([0.0625, 0.0218, 0.1295])\n",
      "z(1) = w(1)* x[1] : tensor([0.1253, 0.1982, 0.1504])\n",
      "z(2) = w(2)* x[2] : tensor([0.1282, 0.1911, 0.1439])\n",
      "z(3) = w(3)* x[3] : tensor([0.0283, 0.0745, 0.0424])\n",
      "z(4) = w(4)* x[4] : tensor([0.0830, 0.0269, 0.0108])\n",
      "z(5) = w(5)* x[5] : tensor([0.0083, 0.1325, 0.0911])\n",
      "\n",
      "context_wrt_query:  torch.Size([1, 3])\n",
      "tensor([[0.4355, 0.6451, 0.5680]])\n",
      "\n",
      "\n",
      "-- vectorize --\n",
      "context shape:  torch.Size([6, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "X = torch.tensor([\n",
    "    [0.43, 0.15, 0.89], # Your     (x^1)\n",
    "    [0.55, 0.87, 0.66], # journey  (x^2)\n",
    "    [0.57, 0.85, 0.64], # starts (x^3)\n",
    "    [0.22, 0.58, 0.33], # with (x^4)\n",
    "    [0.77, 0.25, 0.10], # one (x^5)\n",
    "    [0.05, 0.80, 0.55] # step (x^6)\n",
    "])\n",
    "\n",
    "# simple affinity : dot-product (to measure similarity)\n",
    "def affinity(x, y):\n",
    "    \"\"\"Given 2 vectors, compute affinity\"\"\"\n",
    "    return torch.dot(x, y)\n",
    "\n",
    "# step 1 : calculate attention weights \n",
    "# idea : If query q : how much should each token of input X (i.e. x1, x2, ...) be weighed in importance \n",
    "# attention(query, x) for all x in input\n",
    "query_idx = 1\n",
    "query_token = X[query_idx]\n",
    "attention_weights = torch.tensor([affinity(x_i, query_token) for (_, x_i) in enumerate(X)])\n",
    "attention_weights = torch.tensor([a / attention_weights.sum() for a in attention_weights])\n",
    "attention_weights = attention_weights.view(-1, 1)\n",
    "\n",
    "print(\"\\n\\n-- attention --\")\n",
    "print(f\"token[{query_idx}]: {query_token}\")\n",
    "print(\"A(.) is affinity\")\n",
    "for idx, score in enumerate(attention_weights):\n",
    "    print(f\"w({idx}) = A(x({query_idx}), x({idx})) : {score}\")\n",
    "\n",
    "# step 2 : compute context vectors  \n",
    "# idea : Given query q and attention weights, create \"information context\" using weighted sum approach\n",
    "# idea : \"information context\" tells LLM how to make use of all the input tokens\n",
    "query = X[1]\n",
    "list_context_vectors = attention_weights * X\n",
    "context_vector = list_context_vectors.sum(dim=0, keepdim=True)\n",
    "print(\"\\n\\n-- context --\")\n",
    "print(\"list_context_vectors : \", list_context_vectors.shape)\n",
    "for idx, vec in enumerate(list_context_vectors):\n",
    "    print(f\"z({idx}) = w({idx})* x[{idx}] : {vec}\")\n",
    "\n",
    "print(\"\\ncontext_wrt_query: \", context_vector.shape)\n",
    "print(context_vector)\n",
    "\n",
    "# step 3 - vectorize \n",
    "print(\"\\n\\n-- vectorize --\")\n",
    "attention_scores = X @ X.T # compute attention pair-wise for each x_i, x_j pair using dot-product \n",
    "attention_weights = torch.softmax(attention_scores, dim=-1) # row_i = attention weights w.r.t x_i\n",
    "context_matrix = attention_weights @ X # output (n, k) where each row i is attention_context for x_i\n",
    "print(\"context shape: \", context_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "-- attention scores and weights shapes --\n",
      "attention_scores shape:  torch.Size([6, 6])\n",
      "attention_weights shape:  torch.Size([6, 6])\n",
      "context shape:  torch.Size([6, 3])\n"
     ]
    }
   ],
   "source": [
    "# vectorize attention\n",
    "attention_scores = X @ X.T\n",
    "attention_weights = torch.softmax(attention_scores, dim=-1)\n",
    "context_matrix = attention_weights @ X\n",
    "print(\"\\n\\n-- attention scores and weights shapes --\")\n",
    "print(\"attention_scores shape: \", attention_scores.shape)\n",
    "print(\"attention_weights shape: \", attention_weights.shape)\n",
    "print(\"context shape: \", context_matrix.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
